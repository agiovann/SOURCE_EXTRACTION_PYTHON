{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching the Cnmf-Seeded Components from Ground Truths with the Results of a CNMF Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pylab as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import time\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.base.rois import extract_binary_masks_blob\n",
    "from caiman.utils.visualization import plot_contours, view_patches_bar\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.motion_correction import MotionCorrect, tile_and_correct, motion_correction_piecewise \n",
    "from caiman.components_evaluation import estimate_components_quality, evaluate_components, evaluate_components_CNN\n",
    "from caiman.tests.comparison import comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Up the Ground Truth Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_movie = {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.03.00.test/images/final_map/Yr_d1_498_d2_467_d3_1_order_C_frames_2250_.mmap',\n",
    "                'p': 1,  # order of the autoregressive system\n",
    "                'merge_thresh': 0.8,  # merging threshold, max correlation allow\n",
    "                'rf': 25,  # half-size of the patches in pixels. rf=25, patches are 50x50    20\n",
    "                'stride_cnmf': 10,  # amounpl.it of overlap between the patches in pixels\n",
    "                'K': 4,  # number of components per patch\n",
    "                # if dendritic. In this case you need to set init_method to sparse_nmf\n",
    "                'is_dendrites': False,\n",
    "                'init_method': 'greedy_roi',\n",
    "                'gSig': [8, 8],  # expected half size of neurons\n",
    "                'alpha_snmf': None,  # this controls sparsity\n",
    "                'final_frate': 10,\n",
    "                'r_values_min_patch': .5,  # threshold on space consistency\n",
    "                'fitness_min_patch': -10,  # threshold on time variability\n",
    "                # threshold on time variability (if nonsparse activity)\n",
    "                'fitness_delta_min_patch': -5,\n",
    "                'Npeaks': 5,\n",
    "                'r_values_min_full': .8,\n",
    "                'fitness_min_full': - 40,\n",
    "                'fitness_delta_min_full': - 40,\n",
    "                'only_init_patch': True,\n",
    "                'gnb': 2,\n",
    "                'memory_fact': 1,\n",
    "                'n_chunks': 10,\n",
    "                # whether to update the background components in the spatial phase\n",
    "                'update_background_components': True,\n",
    "                'low_rank_background': True  # whether to update the using a low rank approximation. In the False case all the nonzero elements of the background components are updated using hals\n",
    "                #(to be used with one background per patch)\n",
    "                }\n",
    "\n",
    "params_movie = {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.04.00.test/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_3000_.mmap',\n",
    "                'p': 1,  # order of the autoregressive system\n",
    "                'merge_thresh': 0.8,  # merging threshold, max correlation allow\n",
    "                'rf': 20,  # half-size of the patches in pixels. rf=25, patches are 50x50    20\n",
    "                'stride_cnmf': 10,  # amounpl.it of overlap between the patches in pixels\n",
    "                'K': 5,  # number of components per patch\n",
    "                # if dendritic. In this case you need to set init_method to sparse_nmf\n",
    "                'is_dendrites': False,\n",
    "                'init_method': 'greedy_roi',\n",
    "                'gSig': [5, 5],  # expected half size of neurons\n",
    "                'alpha_snmf': None,  # this controls sparsity\n",
    "                'final_frate': 10,\n",
    "                'r_values_min_patch': .5,  # threshold on space consistency\n",
    "                'fitness_min_patch': -10,  # threshold on time variability\n",
    "                # threshold on time variability (if nonsparse activity)\n",
    "                'fitness_delta_min_patch': -10,\n",
    "                'Npeaks': 5,\n",
    "                'r_values_min_full': .8,\n",
    "                'fitness_min_full': - 40,\n",
    "                'fitness_delta_min_full': - 40,\n",
    "                'only_init_patch': True,\n",
    "                'gnb': 2,\n",
    "                'memory_fact': 1,\n",
    "                'n_chunks': 10,\n",
    "                # whether to update the background components in the spatial phase\n",
    "                'update_background_components': True,\n",
    "                'low_rank_background': True  # whether to update the using a low rank approximation. In the False case all the nonzero elements of the background components are updated using hals\n",
    "                #(to be used with one background per patch)\n",
    "                }\n",
    "\n",
    "params_movie = {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.04.00.test/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_3000_.mmap',\n",
    "                'p': 1,  # order of the autoregressive system\n",
    "                'merge_thresh': 0.8,  # merging threshold, max correlation allow\n",
    "                'rf': 20,  # half-size of the patches in pixels. rf=25, patches are 50x50    20\n",
    "                'stride_cnmf': 10,  # amounpl.it of overlap between the patches in pixels\n",
    "                'K': 5,  # number of components per patch\n",
    "                # if dendritic. In this case you need to set init_method to sparse_nmf\n",
    "                'is_dendrites': False,\n",
    "                'init_method': 'greedy_roi',\n",
    "                'gSig': [5, 5],  # expected half size of neurons\n",
    "                'alpha_snmf': None,  # this controls sparsity\n",
    "                'final_frate': 10,\n",
    "                'r_values_min_patch': .5,  # threshold on space consistency\n",
    "                'fitness_min_patch': -10,  # threshold on time variability\n",
    "                # threshold on time variability (if nonsparse activity)\n",
    "                'fitness_delta_min_patch': -10,\n",
    "                'Npeaks': 5,\n",
    "                'r_values_min_full': .8,\n",
    "                'fitness_min_full': - 40,\n",
    "                'fitness_delta_min_full': - 40,\n",
    "                'only_init_patch': True,\n",
    "                'gnb': 2,\n",
    "                'memory_fact': 1,\n",
    "                'n_chunks': 10,\n",
    "                # whether to update the background components in the spatial phase\n",
    "                'update_background_components': True,\n",
    "                'low_rank_background': True  # whether to update the using a low rank approximation. In the False case all the nonzero elements of the background components are updated using hals\n",
    "                #(to be used with one background per patch)\n",
    "                }\n",
    "\n",
    "# neurofinder 02.00\n",
    "params_movie = {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.02.00/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_8000_.mmap',\n",
    "                'p': 1,  # order of the autoregressive system\n",
    "                'merge_thresh': 0.8,  # merging threshold, max correlation allow\n",
    "                'rf': 20,  # half-size of the patches in pixels. rf=25, patches are 50x50    20\n",
    "                'stride_cnmf': 10,  # amounpl.it of overlap between the patches in pixels\n",
    "                'K': 6,  # number of components per patch\n",
    "                # if dendritic. In this case you need to set init_method to sparse_nmf\n",
    "                'is_dendrites': False,\n",
    "                'init_method': 'greedy_roi',\n",
    "                'gSig': [5, 5],  # expected half size of neurons\n",
    "                'alpha_snmf': None,  # this controls sparsity\n",
    "                'final_frate': 10,\n",
    "                'r_values_min_patch': .5,  # threshold on space consistency\n",
    "                'fitness_min_patch': -10,  # threshold on time variability\n",
    "                # threshold on time variability (if nonsparse activity)\n",
    "                'fitness_delta_min_patch': -10,\n",
    "                'Npeaks': 5,\n",
    "                'r_values_min_full': .8,\n",
    "                'fitness_min_full': - 40,\n",
    "                'fitness_delta_min_full': - 40,\n",
    "                'only_init_patch': True,\n",
    "                'gnb': 2,\n",
    "                'memory_fact': 1,\n",
    "                'n_chunks': 10,\n",
    "                # whether to update the background components in the spatial phase\n",
    "                'update_background_components': True,\n",
    "                'low_rank_background': True,  # whether to update the using a low rank approximation. In the False case all the nonzero elements of the background components are updated using hals\n",
    "                #(to be used with one background per patch)\n",
    "                'swap_dim': False,\n",
    "                'crop_pix': 10\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for the Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_display = {\n",
    "    'downsample_ratio': .2,\n",
    "    'thr_plot': 0.8\n",
    "}\n",
    "\n",
    "# @params fname name of the movie\n",
    "fname_new = params_movie['fname']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MEMMAP File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname_new='Yr_d1_501_d2_398_d3_1_order_F_frames_369_.mmap'\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "d1, d2 = dims\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "Y = np.reshape(Yr, dims + (T,), order='F')\n",
    "m_images = cm.movie(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if m_images.shape[0] < 10000:\n",
    "    Cn = m_images.local_correlations(\n",
    "        swap_dim=params_movie['swap_dim'], frames_per_chunk=1500)\n",
    "    Cn[np.isnan(Cn)] = 0\n",
    "else:\n",
    "    Cn = np.array(cm.load(('/'.join(fname_new.split('/') \n",
    "                                    [:-3] + ['projections', 'correlation_image_better.tif'])))).squeeze()\n",
    "plt.imshow(Cn, cmap='gray', vmax=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% some parameter settings\n",
    "# order of the autoregressive fit to calcium imaging in general one (slow gcamps) or two (fast gcamps fast scanning)\n",
    "p = params_movie['p']\n",
    "# merging threshold, max correlation allowed\n",
    "merge_thresh = params_movie['merge_thresh']\n",
    "# half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "rf = params_movie['rf']\n",
    "# amounpl.it of overlap between the patches in pixels\n",
    "stride_cnmf = params_movie['stride_cnmf']\n",
    "# number of components per patch\n",
    "K = params_movie['K']\n",
    "# if dendritic. In this case you need to set init_method to sparse_nmf\n",
    "is_dendrites = params_movie['is_dendrites']\n",
    "# iinit method can be greedy_roi for round shapes or sparse_nmf for denritic data\n",
    "init_method = params_movie['init_method']\n",
    "# expected half size of neurons\n",
    "gSig = params_movie['gSig']\n",
    "# this controls sparsity\n",
    "alpha_snmf = params_movie['alpha_snmf']\n",
    "# frame rate of movie (even considering eventual downsampling)\n",
    "final_frate = params_movie['final_frate']\n",
    "\n",
    "if params_movie['is_dendrites'] == True:\n",
    "    if params_movie['init_method'] is not 'sparse_nmf':\n",
    "        raise Exception('dendritic requires sparse_nmf')\n",
    "    if params_movie['alpha_snmf'] is None:\n",
    "        raise Exception('need to set a value for alpha_snmf')\n",
    "# %% Extract spatial and temporal components on patches\n",
    "t1 = time.time()\n",
    "# TODO: todocument\n",
    "# TODO: warnings 3\n",
    "cnm = cnmf.CNMF(n_processes=1, k=K, gSig=gSig, merge_thresh=params_movie['merge_thresh'], p=params_movie['p'],\n",
    "                dview=dview, rf=rf, stride=stride_cnmf, memory_fact=1,\n",
    "                method_init=init_method, alpha_snmf=alpha_snmf, only_init_patch=params_movie[\n",
    "                    'only_init_patch'],\n",
    "                gnb=params_movie['gnb'], method_deconvolution='oasis', border_pix=params_movie['crop_pix'], low_rank_background=params_movie['low_rank_background'])\n",
    "cnm = cnm.fit(images)\n",
    "\n",
    "A_tot = cnm.A\n",
    "C_tot = cnm.C\n",
    "YrA_tot = cnm.YrA\n",
    "b_tot = cnm.b\n",
    "f_tot = cnm.f\n",
    "sn_tot = cnm.sn\n",
    "print(('Number of components:' + str(A_tot.shape[-1])))\n",
    "# %%\n",
    "pl.figure()\n",
    "# TODO: show screenshot 12`\n",
    "# TODO : change the way it is used\n",
    "crd = plot_contours(A_tot, Cn, thr=params_display['thr_plot'])\n",
    "\n",
    "# DISCARD LOW QUALITY COMPONENT\n",
    "final_frate = params_movie['final_frate']\n",
    "# threshold on space consistency\n",
    "r_values_min = params_movie['r_values_min_patch']\n",
    "# threshold on time variability\n",
    "fitness_min = params_movie['fitness_delta_min_patch']\n",
    "# threshold on time variability (if nonsparse activity)\n",
    "fitness_delta_min = params_movie['fitness_delta_min_patch']\n",
    "Npeaks = params_movie['Npeaks']\n",
    "traces = C_tot + YrA_tot\n",
    "# TODO: todocument\n",
    "idx_components, idx_components_bad = estimate_components_quality(\n",
    "    traces, Y, A_tot, C_tot, b_tot, f_tot, final_frate=final_frate, Npeaks=Npeaks, r_values_min=r_values_min,\n",
    "    fitness_min=fitness_min, fitness_delta_min=fitness_delta_min)\n",
    "print(('Keeping ' + str(len(idx_components)) +\n",
    "       ' and discarding  ' + str(len(idx_components_bad))))\n",
    "# %%\n",
    "# TODO: show screenshot 13\n",
    "pl.figure()\n",
    "crd = plot_contours(\n",
    "    A_tot.tocsc()[:, idx_components], Cn, thr=params_display['thr_plot'])\n",
    "# %%\n",
    "A_tot = A_tot.tocsc()[:, idx_components]\n",
    "C_tot = C_tot[idx_components]\n",
    "# %% rerun updating the components to refine\n",
    "t1 = time.time()\n",
    "cnm = cnmf.CNMF(n_processes=1, k=A_tot.shape, gSig=gSig, merge_thresh=merge_thresh, p=p, dview=dview, Ain=A_tot,\n",
    "                Cin=C_tot, b_in=b_tot,\n",
    "                f_in=f_tot, rf=None, stride=None, method_deconvolution='oasis', gnb=params_movie['gnb'],\n",
    "                low_rank_background=params_movie['low_rank_background'], update_background_components=params_movie['update_background_components'])\n",
    "\n",
    "cnm = cnm.fit(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, C, b, f, YrA, sn = cnm.A, cnm.C, cnm.b, cnm.f, cnm.YrA, cnm.sn\n",
    "# %% again recheck quality of components, stricter criteria\n",
    "final_frate = params_movie['final_frate']\n",
    "# threshold on space consistency\n",
    "r_values_min = params_movie['r_values_min_full']\n",
    "fitness_min = params_movie['fitness_min_full']  # threshold on time variability\n",
    "# threshold on time variability (if nonsparse activity)\n",
    "fitness_delta_min = params_movie['fitness_delta_min_full']\n",
    "Npeaks = params_movie['Npeaks']\n",
    "traces = C + YrA\n",
    "idx_components, idx_components_bad, fitness_raw, fitness_delta, r_values = estimate_components_quality(\n",
    "    traces, Y, A, C, b, f, final_frate=final_frate, Npeaks=Npeaks, r_values_min=r_values_min, fitness_min=fitness_min,\n",
    "    fitness_delta_min=fitness_delta_min, return_all=True)\n",
    "print(' ***** ')\n",
    "print((len(traces)))\n",
    "print((len(idx_components)))\n",
    "# %% save results\n",
    "np.savez(os.path.join(os.path.split(fname_new)[0], os.path.split(fname_new)[1][:-4] + 'results_analysis.npz'), Cn=Cn, fname_new=fname_new,\n",
    "         A=A,\n",
    "         C=C, b=b, f=f, YrA=YrA, sn=sn, d1=d1, d2=d2, idx_components=idx_components,\n",
    "         idx_components_bad=idx_components_bad,\n",
    "         fitness_raw=fitness_raw, fitness_delta=fitness_delta, r_values=r_values)\n",
    "# we save it\n",
    "# %%\n",
    "# TODO: show screenshot 14\n",
    "pl.subplot(1, 2, 1)\n",
    "crd = plot_contours(A.tocsc()[:, idx_components],\n",
    "                    Cn, thr=params_display['thr_plot'])\n",
    "pl.subplot(1, 2, 2)\n",
    "crd = plot_contours(A.tocsc()[:, idx_components_bad],\n",
    "                    Cn, thr=params_display['thr_plot'])\n",
    "# %%\n",
    "# TODO: needinfo\n",
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A.tocsc()[:, idx_components]), C[idx_components, :], b, f, dims[0], dims[1],\n",
    "                 YrA=YrA[idx_components, :], img=Cn)\n",
    "# %%\n",
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A.tocsc()[:, idx_components_bad]), C[idx_components_bad, :], b, f, dims[0],\n",
    "                 dims[1], YrA=YrA[idx_components_bad, :], img=Cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_display = {\n",
    "    'downsample_ratio': .2,\n",
    "    'thr_plot': 0.8\n",
    "}\n",
    "\n",
    "try:\n",
    "    fname_new = fname_new[()]\n",
    "except:\n",
    "    pass\n",
    "#analysis_file = '/mnt/ceph/neuro/jeremie_analysis/neurofinder.03.00.test/Yr_d1_498_d2_467_d3_1_order_C_frames_2250_._results_analysis.npz'\n",
    "with np.load(os.path.join(os.path.split(fname_new)[0], os.path.split(fname_new)[1][:-4] + 'results_analysis.npz')) as ld:\n",
    "    print(ld.keys())\n",
    "    locals().update(ld)\n",
    "    dims_off = d1, d2\n",
    "    A = scipy.sparse.coo_matrix(A[()])\n",
    "    dims = (d1, d2)\n",
    "    gSig = params_movie['gSig']\n",
    "    fname_new = fname_new[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, final_crops = evaluate_components_CNN(\n",
    "    A, dims, gSig, model_name='model/cnn_model')\n",
    "\n",
    "cm.movie(final_crops).play(gain=3, magnification=6, fr=5)\n",
    "cm.movie(np.squeeze(final_crops[np.where(predictions[:, 1] >= 0.5)[0]])).play(\n",
    "    gain=2., magnification=5, fr=5)\n",
    "cm.movie(np.squeeze(final_crops[np.where(predictions[:, 0] >= 0.5)[0]])).play(\n",
    "    gain=2., magnification=5, fr=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = .5\n",
    "idx_components_cnn = np.where(predictions[:, 1] >= thresh)[0]\n",
    "idx_components_bad_cnn = np.where(predictions[:, 0] > (1 - thresh))[0]\n",
    "\n",
    "print(' ***** ')\n",
    "print((len(final_crops)))\n",
    "print((len(idx_components_cnn)))\n",
    "\n",
    "idx_components_r = np.where((r_values >= .5))[0]\n",
    "idx_components_raw = np.where(fitness_raw < -5)[0]\n",
    "idx_components_delta = np.where(fitness_delta < -5)[0]\n",
    "#idx_and_condition_1 = np.where((r_values >= .65) & ((fitness_raw < -20) | (fitness_delta < -20)) )[0]\n",
    "\n",
    "idx_components = np.union1d(idx_components_r, idx_components_raw)\n",
    "idx_components = np.union1d(idx_components, idx_components_delta)\n",
    "idx_components_bad = np.setdiff1d(list(range(len(r_values))), idx_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' ***** ')\n",
    "print((len(r_values)))\n",
    "print((len(idx_components)))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "crd = plot_contours(A.tocsc()[:, idx_components],\n",
    "                    Cn, thr=params_display['thr_plot'], vmax=0.35)\n",
    "plt.subplot(1, 2, 2)\n",
    "crd = plot_contours(A.tocsc()[:, idx_components_bad],\n",
    "                    Cn, thr=params_display['thr_plot'], vmax=0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)\n",
    "\n",
    "gt_file = os.path.join(os.path.split(fname_new)[0], os.path.split(\n",
    "    fname_new)[1][:-4] + 'match_masks.npz')\n",
    "\n",
    "with np.load(gt_file) as ld:\n",
    "    print(ld.keys())\n",
    "    locals().update(ld)\n",
    "    A_gt = scipy.sparse.coo_matrix(A_gt[()])\n",
    "    dims = (d1, d2)\n",
    "\n",
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A_gt.toarray()[\n",
    "                 :, idx_components_gt]), C_gt[idx_components_gt], b, f, dims[0], dims[1], YrA=YrA_gt[idx_components_gt], img=Cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_A = (normalize(A_gt.tocsc()[:, idx_components_gt], axis=0).T.dot(\n",
    "    normalize(A.tocsc()[:, :], axis=0))).toarray()\n",
    "dist_C = normalize(C_gt[idx_components_gt], axis=1).dot(\n",
    "    normalize(C[:], axis=1).T)\n",
    "dist_A = dist_A * (dist_A > 0)\n",
    "\n",
    "plt.figure(figsize=(30, 20))\n",
    "tp_gt, tp_comp, fn_gt, fp_comp, performance_cons_off = cm.base.rois.nf_match_neurons_in_binary_masks(A_gt.toarray()[:, idx_components_gt].reshape([dims[0], dims[1], -1], order='F').transpose([2, 0, 1]),\n",
    "                                                                                                     A.toarray()[:, :].reshape([dims[0], dims[1], -1], order='F').transpose([2, 0, 1]), thresh_cost=.7, min_dist=10,\n",
    "                                                                                                     print_assignment=False, plot_results=True, Cn=Cn, labels=['GT', 'Offline'], D=[1 - dist_A * (dist_C > .8)])\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "font = {'family': 'Myriad Pro',\n",
    "        'weight': 'regular',\n",
    "        'size': 20}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "idx_final = tp_comp[np.where(dist_A[tp_gt, tp_comp] > 0.7)[0]]\n",
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A.toarray()[\n",
    "                 :, idx_final]), C[idx_final], b, f, dims[0], dims[1], YrA=YrA[idx_final], img=Cn)\n",
    "\n",
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A.toarray()[\n",
    "                 :, fp_comp]), C[fp_comp], b, f, dims[0], dims[1], YrA=YrA[fp_comp], img=Cn)\n",
    "\n",
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A_gt.toarray()[\n",
    "                 :, fn_gt]), C_gt[fn_gt], b_gt, f_gt, dims[0], dims[1], YrA=YrA_gt[fn_gt], img=Cn)\n",
    "\n",
    "plt.hist(r_values[tp_comp], 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(os.path.split(fname_new)[0], os.path.split(fname_new)[1][:-4] + '_training_set.npz'), fname_new=fname_new,\n",
    "         A_seeded=A_gt.tocsc()[\n",
    "    :, idx_components_gt], C_seeded=C_gt[idx_components_gt], YrA_seeded=YrA_gt[idx_components_gt],\n",
    "    A_matched=A.tocsc()[\n",
    "    :, idx_final], C_matched=C[idx_final], YrA_matched=YrA[idx_final],\n",
    "    A_unmatched=A_gt.tocsc()[\n",
    "    :, fn_gt], C_unmatched=C_gt[fn_gt], YrA_unmatched=YrA_gt[fn_gt],\n",
    "    A_negative=A.tocsc()[\n",
    "    :, fp_comp], C_negative=C[fp_comp], YrA_negative=YrA[fp_comp],\n",
    "    r_values=r_values, fitness_delta=fitness_delta, fitness_raw=fitness_raw, Cn=Cn, dims=dims\n",
    ")\n",
    "\n",
    "with np.load(os.path.join(os.path.split(fname_new)[0], os.path.split(fname_new)[1][:-4] + '_training_set.npz')) as ld:\n",
    "    print(ld.keys())\n",
    "    locals().update(ld)\n",
    "    fname_new = fname_new[()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.98\n",
    "pl.subplot(1, 3, 1)\n",
    "crd = plot_contours(A_matched[()], Cn, thr=thr)\n",
    "pl.subplot(1, 3, 2)\n",
    "crd = plot_contours(A_unmatched[()], Cn, thr=thr)\n",
    "pl.subplot(1, 3, 3)\n",
    "crd = plot_contours(A_negative[()], Cn, thr=thr)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "crd = pl.imshow(A_matched[()].sum(1).reshape(\n",
    "    dims, order='F'), vmax=A_matched[()].max() * .2)\n",
    "plt.subplot(1, 3, 2)\n",
    "crd = pl.imshow(A_unmatched[()].sum(1).reshape(\n",
    "    dims, order='F'), vmax=A_unmatched[()].max() * .2)\n",
    "plt.subplot(1, 3, 3)\n",
    "crd = pl.imshow(A_negative[()].sum(1).reshape(\n",
    "    dims, order='F'), vmax=A_negative[()].max() * .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maskings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_sue = scipy.io.loadmat('/mnt/xfs1/home/agiovann/Downloads/yuste_sue_masks.mat')\n",
    "\n",
    "with h5py.File('/mnt/xfs1/home/agiovann/Downloads/yuste_1.protoroi.mat')as f:\n",
    "    print(f.keys())\n",
    "    print(list(f['repository']))\n",
    "    proto = f['prototypes']\n",
    "    print(list(proto['params']))\n",
    "    print(proto.keys())\n",
    "    spatial = proto['spatial']\n",
    "    print(spatial.keys())\n",
    "    locals().update((dict(spatial.attrs.iteritems())))\n",
    "    locals().update({k: np.array(l) for k, l in spatial.iteritems()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman_pytorch",
   "language": "python",
   "name": "caiman_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
